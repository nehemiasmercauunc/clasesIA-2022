<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.14.3/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@6.7.0"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.14.3"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.14.3/dist/index.umd.min.js"></script><script>(r => {
                setTimeout(r);
              })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{"type":"heading","depth":0,"payload":{"lines":[0,1]},"content":"CRISP-DM - Modelo o metodología de Minería de Datos (8/9/22)","children":[{"type":"heading","depth":1,"payload":{"lines":[1,2]},"content":"Características","children":[{"type":"list_item","depth":2,"payload":{"lines":[2,3]},"content":"Cross Industry Standard Process for Data Mining"},{"type":"list_item","depth":2,"payload":{"lines":[3,4]},"content":"Modelo estándar abierto del proceso que describe los enfoques comunes que utilizan los expertos en minería de datos."},{"type":"list_item","depth":2,"payload":{"lines":[4,5]},"content":"Es el modelo analítico más usado."}]},{"type":"heading","depth":1,"payload":{"lines":[5,6]},"content":"Reglas de Comportamiento:","children":[{"type":"heading","depth":2,"payload":{"lines":[6,7]},"content":"Modelo de Machine Learning: TOP DOWN INDUCTION DECISION TREE (TDIDT)","children":[{"type":"list_item","depth":3,"payload":{"lines":[7,8]},"content":"<em>ID3</em>"},{"type":"list_item","depth":3,"payload":{"lines":[8,9]},"content":"<em>C 4.5</em>"},{"type":"list_item","depth":3,"payload":{"lines":[9,10]},"content":"<em>C 5.0</em>"},{"type":"list_item","depth":3,"payload":{"lines":[10,11]},"content":"<em>CART</em>"},{"type":"list_item","depth":3,"payload":{"lines":[11,16]},"content":"<em>RANDOM FOREST</em>:<br>\n- Es una mejora del algoritmo TDIDT, porque tiene incorporada técnicas de regularización.<br>\n- Tiene el metodo de buscar los atributos mas importantes<br>\n- Son los que intervinieron en la desición de las particiones en los nodos interiores.<br>\n- NO ES UNA RELACIÓN CAUSAL."}]},{"type":"heading","depth":2,"payload":{"lines":[16,17]},"content":"Proceso: Descubrimiento de Grupos (Clustering)","children":[{"type":"list_item","depth":3,"payload":{"lines":[17,18]},"content":"Clustering: asociar a los elementos en función de su similitudes."},{"type":"list_item","depth":3,"payload":{"lines":[18,20]},"content":"Cuando se alimenta al algoritmo, se lo alimenta con una métrica que el analista considera válida.<br>\nEl algoritmo toma las métricas como distancias geométricas y las trata de forma igualitaria. CUIDADO CON LAS INTERPRETACIONES DE LOS DATOS."},{"type":"list_item","depth":3,"payload":{"lines":[20,21]},"content":"SOM: algoritmo de Redes neuronales"},{"type":"list_item","depth":3,"payload":{"lines":[21,22]},"content":"No tienen atributos target, no tienen etiquetas. No clasifican. Todos son atributos inputs."},{"type":"list_item","depth":3,"payload":{"lines":[22,23]},"content":"El algoritmo agrupa los datos según las asociaciones y similitudes que encuentra, una vez convertidos los atributos en geometría."},{"type":"list_item","depth":3,"payload":{"lines":[23,24]},"content":"Todos son variables continuas"}]},{"type":"heading","depth":2,"payload":{"lines":[25,26]},"content":"Proceso: Descubrimiento de Atributos Significativos o Interdependencia","children":[{"type":"list_item","depth":3,"payload":{"lines":[27,28]},"content":"Modelo de Machine Learning: Redes Bayesianas"}]},{"type":"heading","depth":2,"payload":{"lines":[29,30]},"content":"Proceso: Descubrimiento de Reglas de Pertenencia a los Grupos","children":[{"type":"list_item","depth":3,"payload":{"lines":[30,31]},"content":"Es una combinaciones de los procesos anteriores"},{"type":"list_item","depth":3,"payload":{"lines":[31,32]},"content":"Se descubren las etiquetas que indican a que cluster pertenece cada ejemplo"},{"type":"list_item","depth":3,"payload":{"lines":[32,33]},"content":"Esa etiqueta, se toma como atributo <em>target</em> de los algoritmos TDIDT"}]}]},{"type":"heading","depth":1,"payload":{"lines":[34,35]},"content":"Mapas AutoOrganizados o Clustering","children":[{"type":"heading","depth":2,"payload":{"lines":[35,36]},"content":"K-MEANS (Algoritmo)","children":[{"type":"list_item","depth":3,"payload":{"lines":[36,37]},"content":"Permite calibrar rápidamente, cuál es el número de cluster óptimo para el dataset a tratar"},{"type":"list_item","depth":3,"payload":{"lines":[37,38]},"content":"Tiene incorporado, la curva ELBOW: mide en función del número de clusters, la inercia."},{"type":"list_item","depth":3,"payload":{"lines":[38,39]},"content":"Mientras las masas esten mas cercanas, la inercia es menor. Esto tiene que ver con la similitud de los datos respecto a los atributos."},{"type":"list_item","depth":3,"payload":{"lines":[39,40]},"content":"La cantidad de clusters a elegir, tiene que ver con la curva ELBOW."},{"type":"list_item","depth":3,"payload":{"lines":[40,41]},"content":"Cada cluster, tiene un centroide."}]},{"type":"heading","depth":2,"payload":{"lines":[42,43]},"content":"HAC (Algoritmo jerárquico)","children":[{"type":"list_item","depth":3,"payload":{"lines":[43,44]},"content":"Jerarquía entre los distintos niveles, determinando la cantidad de clusters por agrupación en cada nivel."},{"type":"list_item","depth":3,"payload":{"lines":[44,47]},"content":"2 Tipos de agrupaciones:<br>\n- Aglomerativa: De abajo hacia arriba.<br>\n- Divisiva: De arriba hacia abajo"},{"type":"list_item","depth":3,"payload":{"lines":[47,48]},"content":"En el nivel mas bajo la similitud es 100% y en el nivel mas alto, la similitud es 0%."},{"type":"list_item","depth":3,"payload":{"lines":[48,49]},"content":"Aglomerativa: Un conjunto de clusters anidados, organizados como un árbol jerárquico, con único cluster arriba, agrupando todos los individuos y clusters con un solo elemeto abajo."},{"type":"list_item","depth":3,"payload":{"lines":[49,50]},"content":"El algoritmo es comparativamente mas lento y no escala bien apra grandes conjuntos de datos"},{"type":"list_item","depth":3,"payload":{"lines":[50,51]},"content":"El algoritmo HAC es sensible a valores atípicos"}]},{"type":"heading","depth":2,"payload":{"lines":[53,54]},"content":"SOM - KOHONEN","children":[{"type":"list_item","depth":3,"payload":{"lines":[54,55]},"content":"Capas de red, conectadas con sinapsis (pesos sinaṕticos)"},{"type":"list_item","depth":3,"payload":{"lines":[55,56]},"content":"Aprendizaje NO supervisado."},{"type":"list_item","depth":3,"payload":{"lines":[56,57]},"content":"Aprende a agrupar los ejemplos según las similitudes que descubre entre ellos."},{"type":"list_item","depth":3,"payload":{"lines":[57,58]},"content":"No usa descenso por el gradiente"}]}]},{"type":"heading","depth":1,"payload":{"lines":[59,60]},"content":"K-MEANS - CLUSTERING","children":[{"type":"list_item","depth":2,"payload":{"lines":[60,61]},"content":"Obtendremos Centroides y Conjuntos o agreupamientos de los ejemplos a los que se enfrente el algoritmo"},{"type":"list_item","depth":2,"payload":{"lines":[61,62]},"content":"Al finalizar, el algoritmo ha etiquetado automáticamente los datos asignándoles una partición o cluster"}]}]},{})</script>
</body>
</html>
